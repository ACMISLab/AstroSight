{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from keras.layers import Activation, Conv2D, Dropout\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D,AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows=224\n",
    "num_classes=8  \n",
    "img_cols=224\n",
    "num_channel=3\n",
    "\n",
    "import splitfolders\n",
    "splitfolders.ratio(\n",
    "    input='/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/gz2_images_dataset07',\n",
    "    output=\"/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/output_dataset\",\n",
    "    seed=1337,\n",
    "    ratio=(0.79,0.01,0.2)  \n",
    ")\n",
    "\n",
    "TRAINING_DIR = \"/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/output_dataset/train\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.0)  \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    batch_size=8,  \n",
    "    class_mode='categorical',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_DIR = '/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/output_dataset/val'\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_DIR,\n",
    "    batch_size=8,  \n",
    "    class_mode='categorical',\n",
    "    target_size=(img_rows, img_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255.0)  \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    batch_size=8,  \n",
    "    class_mode='categorical',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438c66f3",
   "metadata": {},
   "source": [
    "## ECA module Based CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080208ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "input_shape=(224,224,3)\n",
    "##mini_exceptin\n",
    "\n",
    "img_input = Input(input_shape)\n",
    "x = SeparableConv2D(32, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x_offset = Activation('relu')(x)\n",
    "\n",
    "\n",
    "x_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual = SeparableConv2D(32, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual = BatchNormalization()(residual)\n",
    "residual=Activation('relu')(residual)\n",
    "\n",
    "\n",
    "\n",
    "residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40089255",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual1 = SeparableConv2D(32, (5, 5), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual1 = BatchNormalization()(residual1)\n",
    "residual1=Activation('relu')(residual1)\n",
    "\n",
    "\n",
    "\n",
    "residual1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7153ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual2 = SeparableConv2D(32, (7, 7), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual2 = BatchNormalization()(residual2)\n",
    "residual2=Activation('relu')(residual2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf55b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling2D, Reshape, Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fabacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eca_module(x, k_size=5):\n",
    "    squeeze = GlobalAveragePooling2D()(x)\n",
    "    attn = Conv1D(filters=1,\n",
    "                            kernel_size=k_size,\n",
    "                            padding='same',\n",
    "                            kernel_initializer='he_normal',\n",
    "                            use_bias=False)(tf.expand_dims(squeeze, axis=1))\n",
    "    attn = tf.math.sigmoid(tf.expand_dims(tf.transpose(attn, [0, 2, 1]), axis=3))\n",
    "    scale = x * attn\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_attention_map=eca_module(x_offset)\n",
    "channel_attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "x11 = layers.add([residual1,residual,residual2,channel_attention_map])\n",
    "x11.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375cce5d",
   "metadata": {},
   "source": [
    "## Dilation Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  SeparableConv2D(64, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x11)\n",
    "x = BatchNormalization()(x)\n",
    "x_offset = Activation('relu')(x)\n",
    "x_offset = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x_offset)\n",
    "\n",
    "x_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual = SeparableConv2D(64, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",activation='relu',kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual = BatchNormalization()(residual)\n",
    "residual=Activation('relu')(residual)\n",
    "\n",
    "\n",
    "\n",
    "residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa084b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual1 = SeparableConv2D(64, (5, 5), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",activation='relu',kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual1 = BatchNormalization()(residual1)\n",
    "residual2=Activation('relu')(residual1)\n",
    "\n",
    "\n",
    "\n",
    "residual2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8228972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual3 = SeparableConv2D(64, (7, 7), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",activation='relu',kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual3 = BatchNormalization()(residual3)\n",
    "residual3=Activation('relu')(residual3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eca_module(x, k_size=5):\n",
    "    squeeze = GlobalAveragePooling2D()(x)\n",
    "    attn = Conv1D(filters=1,\n",
    "                            kernel_size=k_size,\n",
    "                            padding='same',\n",
    "                            kernel_initializer='he_normal',\n",
    "                            use_bias=False)(tf.expand_dims(squeeze, axis=1))\n",
    "    attn = tf.math.sigmoid(tf.expand_dims(tf.transpose(attn, [0, 2, 1]), axis=3))\n",
    "    scale = x * attn\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_attention_map=eca_module(x_offset)\n",
    "channel_attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "x11 = layers.add([residual2,residual,channel_attention_map,residual3])\n",
    "x11.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a743b1",
   "metadata": {},
   "source": [
    "## Dilation Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  SeparableConv2D(128, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x11)\n",
    "x = BatchNormalization()(x)\n",
    "x_offset = Activation('relu')(x)\n",
    "x_offset = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x_offset)\n",
    "\n",
    "x_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual = SeparableConv2D(128, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual = BatchNormalization()(residual)\n",
    "residual=Activation('relu')(residual)\n",
    "\n",
    "\n",
    "\n",
    "residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module 1\n",
    "residual1 = SeparableConv2D(128, (5, 5), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual1 = BatchNormalization()(residual1)\n",
    "residual12=Activation('relu')(residual1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual1 = SeparableConv2D(128, (5, 5), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x_offset)\n",
    "residual1 = BatchNormalization()(residual1)\n",
    "residual13=Activation('relu')(residual1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5241f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eca_module(x, k_size=5):\n",
    "    squeeze = GlobalAveragePooling2D()(x)\n",
    "    attn = Conv1D(filters=1,\n",
    "                            kernel_size=k_size,\n",
    "                            padding='same',\n",
    "                            kernel_initializer='he_normal',\n",
    "                            use_bias=False)(tf.expand_dims(squeeze, axis=1))\n",
    "    attn = tf.math.sigmoid(tf.expand_dims(tf.transpose(attn, [0, 2, 1]), axis=3))\n",
    "    scale = x * attn\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_attention_map=eca_module(x_offset)\n",
    "channel_attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925365c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x11 = layers.add([residual12,residual,residual13,channel_attention_map])\n",
    "x11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda756e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  SeparableConv2D(256, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x11)\n",
    "x = BatchNormalization()(x)\n",
    "x_offset = Activation('relu')(x)\n",
    "\n",
    "x_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4916d3",
   "metadata": {},
   "source": [
    "## Dilation Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18569bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  SeparableConv2D(256, (3, 3), strides=(1, 1), padding='same',depthwise_initializer='he_normal',pointwise_initializer=\"he_normal\",kernel_regularizer='l1', use_bias=False)(x11)\n",
    "x = BatchNormalization()(x)\n",
    "x_offset = Activation('relu')(x)\n",
    "\n",
    "x_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x15=GlobalAveragePooling2D()(x_offset)\n",
    "x15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de673682",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dropout(0.3)(x15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1485268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94117411",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=Dense(8, activation='softmax')(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(img_input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92606a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf36b661",
   "metadata": {},
   "source": [
    "# DIAT-DSCNN-ECA on GZ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  learning_rate = 0.01\n",
    "  if epoch > 10:\n",
    "    learning_rate = 0.002\n",
    "  if epoch > 25:\n",
    "    learning_rate = 0.001\n",
    "  if epoch > 35:\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\n",
    "model.layers[0].output_shape\n",
    "model.layers[0].get_weights()\n",
    "#np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ed0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_generator,validation_data = validation_generator,steps_per_epoch=3482//8,validation_steps=745//8,epochs=100,batch_size=16, verbose=1)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "history = model.fit(train_generator,validation_data = validation_generator,epochs=80,batch_size=32, verbose=1,callbacks=[ lr_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/New_gz2-path-2block_adam_CNN_0.7_0.15_0.15_224x224xx3_30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926120ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# new_model = load_model('/content/drive/MyDrive/galaxyzoo2_3block_adam_with_ECA_256x256x3_k=5_0.7_0.15_0.15.h5')\n",
    "model = load_model('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/New_gz2-path-2block_adam_CNN_0.7_0.15_0.15_224x224xx3_30.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ec5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "main = '/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/output_dataset/test'\n",
    "\n",
    "sorted_classes = sorted(os.listdir(main))  \n",
    "\n",
    "test_preprocessed_images = []\n",
    "\n",
    "for class_name in tqdm(sorted_classes, desc='Processing Classes'):\n",
    "    class_dir = os.path.join(main, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue  \n",
    "    \n",
    "    image_files = sorted(os.listdir(class_dir))  \n",
    "    for img_name in tqdm(image_files, desc=f'Class {class_name}', leave=False):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        processed = preprocess_image(img_path)  \n",
    "        test_preprocessed_images.append(processed)\n",
    "\n",
    "test_preprocessed_images = np.vstack(test_preprocessed_images)\n",
    "np.save('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Classification-Using-CNN/test_preproc_CNN.npy', test_preprocessed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true, answer)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e29baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = cm.round(2)\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        cm=cm\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools  \n",
    "\n",
    "conf_mat = confusion_matrix(y_true, answer)\n",
    "\n",
    "class_names = [\n",
    "    \"barred_spirals\",          # 0\n",
    "    \"cigar_shaped_elliptical\", # 1\n",
    "    \"edge_on\",                 # 2\n",
    "    \"in_between_elliptical\",   # 3\n",
    "    \"irregular\",               # 4\n",
    "    \"merger\",                  # 5\n",
    "    \"round_elliptical\",        # 6\n",
    "    \"unbarred_spirals\"         # 7\n",
    "]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.round(cm, 2)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.figure(figsize=(14, 12)) \n",
    "plot_confusion_matrix(conf_mat, class_names, normalize=True, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de21ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a990e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695d0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4629c752",
   "metadata": {},
   "source": [
    "## Install Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e723325",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install vit_pytorch linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms, utils\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# vision transformer\n",
    "from linformer import Linformer\n",
    "from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4022d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Galaxy Zoo 2 Dataset\n",
    "class GalaxyZooDataset(Dataset):\n",
    "    \"\"\"Galaxy Zoo Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, images_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): path to the label csv\n",
    "            images_dir (string): path to the dir containing all images\n",
    "            transform (callable, optional): transform to apply\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "        self.labels_df = self.labels_df[['galaxyID', 'label1']].copy()\n",
    "\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the size of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the idx-th sample.\n",
    "\t\tOutputs the image (channel first) and the true label\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # galaxy ID\n",
    "        galaxyid = self.labels_df.iloc[idx, 0].astype(str)\n",
    "\t\t# path of the image\n",
    "        image_path = os.path.join(self.images_dir, galaxyid + '.jpg')\n",
    "\t\t# read the image\n",
    "        image = Image.open(image_path)\n",
    "\t\t# apply transform (optional)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\t\t# read the true label\n",
    "        label = int(self.labels_df.iloc[idx, 1])\n",
    "\n",
    "        return image, label, int(galaxyid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8576bf",
   "metadata": {},
   "source": [
    "## Custom Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_transforms(is_for_inception=False):\n",
    "    \"\"\"\n",
    "    Create Pytorch data transforms for the GalaxyZoo datasets.\n",
    "    Args:\n",
    "        is_for_inception (bool): True for inception neural networks\n",
    "    Outputs:\n",
    "        train_transform: transform for the training data\n",
    "        test_transform: transform for the testing data\n",
    "    \"\"\"\n",
    "    if is_for_inception:\n",
    "        input_size = 299\n",
    "    else:\n",
    "        input_size = 224\n",
    "\n",
    "    # transforms for training data\n",
    "    train_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
    "                                          transforms.RandomRotation(90),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.094, 0.0815, 0.063], [0.1303, 0.11, 0.0913])])\n",
    "\n",
    "    # transforms for validation data\n",
    "    valid_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.094, 0.0815, 0.063], [0.1303, 0.11, 0.0913])])\n",
    "\n",
    "    # transforms for test data\n",
    "    test_transform = transforms.Compose([transforms.CenterCrop(input_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.094, 0.0815, 0.063], [0.1303, 0.11, 0.0913])])\n",
    "\n",
    "    \n",
    "    return train_transform, valid_transform, test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10c5e1",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4062d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, criterion, optimizer, scheduler, print_every=1, early_stop_epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    Args:\n",
    "        model: Pytorch neural model\n",
    "        num_epochs: number of epochs to train\n",
    "        criterion: the loss function object\n",
    "        optimizer: the optimizer\n",
    "        scheduler: the learning rate decay scheduler\n",
    "        print_every: print the information every X epochs\n",
    "        early_stop_epochs: early stopping if the model doesn't improve after X epochs\n",
    "    \"\"\"\n",
    "    # cache the best model\n",
    "    best_model_weights = deepcopy(model.state_dict())\n",
    "    # best train acc\n",
    "    best_train_acc = 0.0\n",
    "    # best valid acc\n",
    "    best_valid_acc = 0.0\n",
    "    # best epoch\n",
    "    best_epoch = -1    \n",
    "\n",
    "    # intiate dict to records the history of loss and acc\n",
    "    history_dic = dict()\n",
    "    history_dic['train_loss'] = []\n",
    "    history_dic['train_acc'] = []\n",
    "    history_dic['valid_loss'] = []\n",
    "    history_dic['valid_acc'] = []\n",
    "    history_dic['lr'] = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # time of start\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        \"\"\"\n",
    "        Train\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "\n",
    "        epoch_train_cum_loss = 0.0\n",
    "        epoch_train_cum_corrects = 0\n",
    "        \n",
    "        for images, labels, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_logits = model(images)\n",
    "            loss = criterion(pred_logits, labels)\n",
    "\n",
    "            _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
    "            pred_classes = pred_classes.long()\n",
    "\n",
    "            epoch_train_cum_loss += loss.item() * images.size(0)\n",
    "            epoch_train_cum_corrects += torch.sum(pred_classes==labels.data).detach().to('cpu').item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \"\"\"\n",
    "        Eval\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "\n",
    "        epoch_valid_cum_loss = 0.0\n",
    "        epoch_valid_cum_corrects = 0\n",
    "\n",
    "        for images, labels, _ in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_logits = model(images)\n",
    "                _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
    "                loss = criterion(pred_logits, labels)\n",
    "\n",
    "                epoch_valid_cum_loss += loss.item() * images.size(0)\n",
    "                epoch_valid_cum_corrects += torch.sum(pred_classes==labels.data).detach().to('cpu').item()\n",
    "\n",
    "        ## Calculate metrics\n",
    "        train_loss = epoch_train_cum_loss / len(data_train)\n",
    "        train_acc = epoch_train_cum_corrects / len(data_train)\n",
    "        valid_loss = epoch_valid_cum_loss / len(data_valid)\n",
    "        valid_acc = epoch_valid_cum_corrects / len(data_valid)\n",
    "\n",
    "        # update history_dic\n",
    "        history_dic['train_loss'].append(train_loss)\n",
    "        history_dic['train_acc'].append(train_acc)\n",
    "        history_dic['valid_loss'].append(valid_loss)\n",
    "        history_dic['valid_acc'].append(valid_acc)\n",
    "        history_dic['lr'].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        # check if is the best acc ever\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_train_acc = train_acc\n",
    "            best_valid_acc = valid_acc\n",
    "            best_epoch = epoch + 1\n",
    "            # update the best model weights\n",
    "            best_model_weights = deepcopy(model.state_dict())\n",
    "            # save the best model weights to Google drive\n",
    "            torch.save(model.state_dict(), os.path.join('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Zoo-Classification/dataset_07', model_name + \"_cache.pth\"))\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time_used = epoch_end_time - epoch_start_time\n",
    "        # convert epoch_time_used into mm:ss\n",
    "        mm = epoch_time_used // 60\n",
    "        ss = epoch_time_used % 60\n",
    "\n",
    "        ## Print metrics\n",
    "        if (epoch+1) % print_every == 0:\n",
    "\n",
    "            # if is best valid acc\n",
    "            if epoch == (best_epoch - 1):\n",
    "                print(\"Epoch {}/{}\\tTrain loss: {:.4f}\\tTrain acc: {:.4f}\\tValid loss: {:.4f}\\tValid acc: {:.4f}\\tTime: {:.0f}m {:.0f}s\\t<--\".format(\n",
    "                    epoch+1, num_epochs, train_loss, train_acc, valid_loss, valid_acc, mm, ss))\n",
    "            # not a better model\n",
    "            else:\n",
    "                print(\"Epoch {}/{}\\tTrain loss: {:.4f}\\tTrain acc: {:.4f}\\tValid loss: {:.4f}\\tValid acc: {:.4f}\\tTime: {:.0f}m {:.0f}s\".format(\n",
    "                    epoch+1, num_epochs, train_loss, train_acc, valid_loss, valid_acc, mm, ss))\n",
    "            \n",
    "        ## Early stopping\n",
    "        if (epoch+1) - best_epoch >= early_stop_epochs:\n",
    "            print(\"Early stopping... (Model did not improve after {} epochs)\".format(early_stop_epochs))\n",
    "            break\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # load the best weights into the model\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    # print the best epoch\n",
    "    print(\"Best epoch = {}, with training accuracy = {:.4f} and validation accuracy = {:.4f}\".format(best_epoch, best_train_acc, best_valid_acc))\n",
    "\n",
    "    # return the best model\n",
    "    return model, history_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 原始图像数据根目录\n",
    "root_dir = '/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/gz2_images_dataset07'\n",
    "\n",
    "# 自动提取类别目录并排序\n",
    "class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# 遍历并记录所有图像路径和标签\n",
    "records = []\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith('.jpg'):\n",
    "            galaxy_id = os.path.splitext(fname)[0]\n",
    "            records.append({'galaxyID': galaxy_id, 'label1': class_to_idx[class_name], 'src_path': os.path.join(class_dir, fname)})\n",
    "\n",
    "df_all = pd.DataFrame(records)\n",
    "df_all.to_csv('gz2_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_all = pd.read_csv('gz2_all.csv')\n",
    "\n",
    "# Step 1: 训练集 + 临时集（0.79 vs 0.21）\n",
    "df_train, df_temp = train_test_split(df_all, test_size=0.21, stratify=df_all['label1'], random_state=42)\n",
    "\n",
    "# Step 2: 临时集分为验证集和测试集（0.01 / (0.01+0.2) ≈ 0.0476）\n",
    "df_valid, df_test = train_test_split(df_temp, test_size=0.9524, stratify=df_temp['label1'], random_state=42)\n",
    "\n",
    "# 保存\n",
    "df_train[['galaxyID', 'label1']].to_csv('gz2_train.csv', index=False)\n",
    "df_valid[['galaxyID', 'label1']].to_csv('gz2_valid.csv', index=False)\n",
    "df_test[['galaxyID', 'label1']].to_csv('gz2_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88992847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_images(df, split_name):\n",
    "    dst_dir = f'images_{split_name}'\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        src = row['src_path']\n",
    "        dst = os.path.join(dst_dir, f\"{row['galaxyID']}.jpg\")\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "# 读取包含 src_path 的完整数据\n",
    "df_all_full = pd.read_csv('gz2_all.csv')\n",
    "df_train_full = df_all_full[df_all_full['galaxyID'].isin(pd.read_csv('gz2_train.csv')['galaxyID'])]\n",
    "df_valid_full = df_all_full[df_all_full['galaxyID'].isin(pd.read_csv('gz2_valid.csv')['galaxyID'])]\n",
    "df_test_full = df_all_full[df_all_full['galaxyID'].isin(pd.read_csv('gz2_test.csv')['galaxyID'])]\n",
    "\n",
    "# 复制图像\n",
    "copy_images(df_train_full, 'train')\n",
    "copy_images(df_valid_full, 'valid')\n",
    "copy_images(df_test_full, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c458e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Loader\n",
    "\"\"\"\n",
    "# the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# create transforms\n",
    "train_transform, valid_transform, test_transform = create_data_transforms(is_for_inception=False)\n",
    "\n",
    "# create datasets\n",
    "data_train = GalaxyZooDataset('gz2_train.csv', 'images_train', train_transform)\n",
    "data_valid = GalaxyZooDataset('gz2_valid.csv', 'images_valid', valid_transform)\n",
    "data_test = GalaxyZooDataset('gz2_test.csv', 'images_test', test_transform)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(data_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# check the sizes\n",
    "print(\"**Dataloaders**\")\n",
    "print(\"Number of training data: {} ({} batches)\".format(len(data_train), len(train_loader)))\n",
    "print(\"Number of validation data: {} ({} batches)\".format(len(data_valid), len(valid_loader)))\n",
    "print(\"Number of test data: {} ({} batches)\".format(len(data_test), len(test_loader)))\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbc51d",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "PATCH_SIZE = 28\n",
    "DEPTH = 12\n",
    "HIDDEN_DIM = 128\n",
    "K_DIM = 64\n",
    "NUM_HEADS = 8\n",
    "\n",
    "LR = 3e-4\n",
    "STEP_SIZE = 5\n",
    "GAMMA = 0.9\n",
    "MAX_EPOCH = 200\n",
    "\n",
    "LIN_DROPOUT = 0.1\n",
    "\n",
    "# loss calculation for each class\n",
    "#class_weights = torch.FloatTensor([1., 1., 2., 1., 1., 1., 4., 3.]).to(device)\n",
    "#class_weights = torch.FloatTensor([4.6, 4.0, 20.9, 9.6, 7.7, 5.1, 26.5, 73.3]).to(device)\n",
    "class_weights = torch.FloatTensor([1., 1., 1., 1., 1., 1., 1., 1.]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea065d52",
   "metadata": {},
   "source": [
    "## Create ViT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file name\n",
    "model_name = \"gz2_vit_0511_1849\"\n",
    "\n",
    "# calculate seq_len\n",
    "seq_len = int((224/PATCH_SIZE)**2) + 1\n",
    "\n",
    "## Linformer\n",
    "lin = Linformer(dim=HIDDEN_DIM, seq_len=seq_len, depth=DEPTH, k=K_DIM, heads=NUM_HEADS,\n",
    "                dim_head=None, one_kv_head=False, share_kv=False, reversible=False, dropout=LIN_DROPOUT)\n",
    "\n",
    "## Vision Transformer\n",
    "model = ViT(image_size=224, patch_size=PATCH_SIZE, num_classes=8, dim=HIDDEN_DIM, transformer=lin, pool='cls', channels=3)\n",
    "\n",
    "# print out model details\n",
    "print(\"*******[ \" + model_name + \" ]*******\")\n",
    "print(\"===============================\")\n",
    "print(\"patch_size = {}\".format(PATCH_SIZE))\n",
    "print(\"depth = {}\".format(DEPTH))\n",
    "print(\"hidden_dim = {}\".format(HIDDEN_DIM))\n",
    "print(\"k_dim = {}\".format(K_DIM))\n",
    "print(\"num_heads = {}\".format(NUM_HEADS))\n",
    "print(\"dropout = {}\".format(LIN_DROPOUT))\n",
    "print(\"batch_size = {}\".format(BATCH_SIZE))\n",
    "print(\"lr = {}\".format(LR))\n",
    "print(\"step_size = {}\".format(STEP_SIZE))\n",
    "print(\"gamma = {}\".format(GAMMA))\n",
    "print(\"max_epoch = {}\".format(MAX_EPOCH))\n",
    "print(\"class weights = {}\".format(class_weights))\n",
    "print(\"===============================\")\n",
    "print(\"Number of trainable parameters: {}\".format(sum(param.numel() for param in model.parameters() if param.requires_grad)))\n",
    "print(\"===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a018a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to gpu\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "## train and return the best model\n",
    "model, history_dic = train_model(model, MAX_EPOCH, criterion, optimizer, scheduler, print_every=1, early_stop_epochs=10)\n",
    "\n",
    "## Save the best weights\n",
    "torch.save(model.state_dict(), model_name + '.pth')\n",
    "torch.save(model.state_dict(), os.path.join('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Zoo-Classification/dataset_07', model_name + '.pth'))\n",
    "\n",
    "## Convert history to dataframe\n",
    "history_df = pd.DataFrame(history_dic)\n",
    "\n",
    "## Save the history\n",
    "history_df.to_csv(model_name + '_history.csv', index=False)\n",
    "history_df.to_csv(os.path.join('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Zoo-Classification/dataset_07', model_name + '_history.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Zoo-Classification/dataset_07', model_name + '_cache.pth')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631312b8",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model):\n",
    "    \"\"\"\n",
    "    Predict test data\n",
    "    \"\"\"\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "\n",
    "    # empty lists for results\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_label = []\n",
    "\n",
    "    for images, labels, galaxy_id in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_logits = model(images)\n",
    "            _, pred_classes = torch.max(pred_logits.detach(), dim=1)\n",
    "\n",
    "            y_true += torch.squeeze(labels.cpu()).tolist()\n",
    "            y_pred += torch.squeeze(pred_classes).tolist()\n",
    "            y_label += torch.squeeze(galaxy_id.cpu()).tolist()\n",
    "    \n",
    "    # create a DataFrame with columns 'GalaxyID', 'class', 'predicted labels'\n",
    "    predict_df = pd.DataFrame(data={'GalaxyID': y_label, 'class': y_true, 'pred': y_pred})\n",
    "\n",
    "    return y_true, y_pred, predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abff91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to gpu\n",
    "model = model.to(device)\n",
    "\n",
    "# model evaluation\n",
    "y_true, y_pred, predict_df = predict_model(model)\n",
    "\n",
    "# save predict_df\n",
    "predict_df.to_csv(model_name + '_predictions.csv', index=False)\n",
    "predict_df.to_csv(os.path.join('/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Galaxy-Zoo-Classification/dataset_07', model_name + '_predictions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4fdf5",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# galaxy classes\n",
    "# gxy_labels = ['Round Elliptical',\n",
    "#               'In-between Elliptical',\n",
    "#               'Cigar-shaped Elliptical',\n",
    "#               'Edge-on Spiral',\n",
    "#               'Barred Spiral',\n",
    "#               'Unbarred Spiral',\n",
    "#               'Irregular',\n",
    "#               'Merger']\n",
    "gxy_labels = [\n",
    "    'Barred Spiral',            # label0\n",
    "    'Cigar-shaped Elliptical',  # label1\n",
    "    'Edge-on',                  # label2\n",
    "    'In-between Elliptical',    # label3\n",
    "    'Irregular',                # label4\n",
    "    'Merger',                   # label5\n",
    "    'Round Elliptical',         # label6\n",
    "    'Unbarred Spiral'           # label7\n",
    "]\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "cm_df = pd.DataFrame(cm, index=gxy_labels, columns=gxy_labels)\n",
    "\n",
    "# accuracy of each class\n",
    "for c in range(8):\n",
    "    print(\"Class {}: accuracy = {:.4f} ({})\".format(c, cm[c,c]/sum(cm[c,:]), gxy_labels[c]))\n",
    "print(\"================\")\n",
    "\n",
    "# accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Total Accuracy = {:.4f}\\n\".format(acc))\n",
    "\n",
    "# recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "print(\"Recall = {:.4f}\\n\".format(recall))\n",
    "\n",
    "# f1 score\n",
    "F1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(\"F1 score = {:.4f}\\n\".format(F1))\n",
    "\n",
    "# plot confusion matrix\n",
    "sns.set(font_scale=1.6)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\".1%\", cmap=\"YlGnBu\", cbar=False, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e2045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e37c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0768f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a7eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831ea5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b79fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

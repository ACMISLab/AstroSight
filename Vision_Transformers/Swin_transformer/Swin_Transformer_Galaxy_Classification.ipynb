{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5659a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 环境设置和GPU配置\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import SwinForImageClassification, SwinConfig\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# 检查GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU名称: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 数据路径和参数设置\n",
    "DATA_PATH = \"/remote-home/cs_acmis_hby/Galaxy-Zoo-Classification/Contrast_experiment/Modern CNNs/Galaxy-Classification-Using-CNN/output_dataset\"\n",
    "\n",
    "# 实验参数\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Swin Transformer推荐较小batch size\n",
    "NUM_CLASSES = 8\n",
    "EPOCHS = 50  # 根据论文表格中的设置\n",
    "LEARNING_RATE = 5e-5  # 预训练模型推荐学习率\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "# 类别名称\n",
    "CLASS_NAMES = [\n",
    "    'barred_spirals',\n",
    "    'cigar_shaped_elliptical', \n",
    "    'edge_on',\n",
    "    'in_between_elliptical',\n",
    "    'irregular',\n",
    "    'merger',\n",
    "    'round_elliptical',\n",
    "    'unbarred_spirals'\n",
    "]\n",
    "\n",
    "print(f\"🎯 实验配置:\")\n",
    "print(f\"   数据路径: {DATA_PATH}\")\n",
    "print(f\"   图像大小: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   批次大小: {BATCH_SIZE}\")\n",
    "print(f\"   类别数: {NUM_CLASSES}\")\n",
    "print(f\"   学习率: {LEARNING_RATE}\")\n",
    "print(f\"   最大轮数: {EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 数据集类和数据加载\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 加载所有图像路径和标签\n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_file in glob.glob(os.path.join(class_dir, '*.jpg')):\n",
    "                    self.images.append(img_file)\n",
    "                    self.labels.append(class_idx)\n",
    "        \n",
    "        print(f\"📁 {data_dir.split('/')[-1]} 数据加载:\")\n",
    "        print(f\"   总样本数: {len(self.images)}\")\n",
    "        \n",
    "        # 统计各类别样本数\n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "            count = self.labels.count(class_idx)\n",
    "            print(f\"   {class_name}: {count}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 加载图像\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# 数据变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(180),  # 天文图像可任意旋转\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "print(\"🔄 创建数据集...\")\n",
    "train_dataset = GalaxyDataset(os.path.join(DATA_PATH, 'train'), transform=train_transform)\n",
    "val_dataset = GalaxyDataset(os.path.join(DATA_PATH, 'val'), transform=val_test_transform)\n",
    "test_dataset = GalaxyDataset(os.path.join(DATA_PATH, 'test'), transform=val_test_transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"\\n✅ 数据加载器创建完成:\")\n",
    "print(f\"   训练批次: {len(train_loader)}\")\n",
    "print(f\"   验证批次: {len(val_loader)}\")\n",
    "print(f\"   测试批次: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206baf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 加载官方预训练Swin Transformer模型\n",
    "print(\"🔧 加载官方Swin Transformer模型...\")\n",
    "\n",
    "# 使用Hugging Face官方预训练模型\n",
    "model = SwinForImageClassification.from_pretrained(\n",
    "    \"microsoft/swin-base-patch4-window7-224\",\n",
    "    num_labels=NUM_CLASSES,\n",
    "    ignore_mismatched_sizes=True  # 忽略分类头大小不匹配\n",
    ").to(device)\n",
    "\n",
    "# 模型信息\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"✅ 模型加载成功!\")\n",
    "print(f\"   模型: microsoft/swin-base-patch4-window7-224\")\n",
    "print(f\"   总参数量: {total_params:,}\")\n",
    "print(f\"   可训练参数: {trainable_params:,}\")\n",
    "print(f\"   预训练: ImageNet-22K → ImageNet-1K\")\n",
    "print(f\"   论文引用: Liu et al. (2021) - Swin Transformer V1\")\n",
    "\n",
    "# 设置优化器和调度器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"\\n📋 训练配置:\")\n",
    "print(f\"   优化器: AdamW\")\n",
    "print(f\"   学习率调度: Cosine Annealing\")\n",
    "print(f\"   损失函数: CrossEntropyLoss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 训练和验证函数\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss/len(train_loader), 100.*correct/total\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return running_loss/len(val_loader), 100.*correct/total\n",
    "\n",
    "print(\"✅ 训练函数定义完成!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e922e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 开始训练\n",
    "print(f\"🚀 开始训练官方Swin Transformer...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}:\")\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 记录历史\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'swin_transformer_official_best.pth')\n",
    "        print(f\"✅ 新的最佳验证准确率: {best_val_acc:.2f}%\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"⏹️ Early stopping after {patience} epochs without improvement\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n✅ 训练完成!\")\n",
    "print(f\"   最佳验证准确率: {best_val_acc:.2f}%\")\n",
    "print(f\"   实际训练轮数: {epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 测试集评估\n",
    "print(\"📊 测试集评估...\")\n",
    "\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('swin_transformer_classification_best.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100. * correct / total\n",
    "test_loss = test_loss / len(test_loader)\n",
    "\n",
    "print(f\"\\n🎯 测试结果:\")\n",
    "print(f\"   测试准确率: {test_accuracy:.2f}%\")\n",
    "print(f\"   测试损失: {test_loss:.4f}\")\n",
    "\n",
    "# 计算F1分数\n",
    "f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"   Macro F1-Score: {f1_macro:.4f}\")\n",
    "print(f\"   Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "\n",
    "# 详细分类报告\n",
    "print(f\"\\n📋 详细分类报告:\")\n",
    "print(classification_report(all_labels, all_predictions, \n",
    "                          target_names=CLASS_NAMES, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2fc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5a85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
